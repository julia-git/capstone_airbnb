{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sf_2017 = pickle.load(open('../data_sf_2017.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sf_2017 = pd.read_json('df_sf_2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117262"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sf_2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sf_2017.space.fillna(value='None', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sf_2017[\"space_new\"] = df_sf_2017['space'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'floor': 30,\n",
       " 'breath': 15,\n",
       " 'taking': 86,\n",
       " 'view': 96,\n",
       " 'easy': 25,\n",
       " 'transportation': 91,\n",
       " 'downtown': 24,\n",
       " 'great': 35,\n",
       " 'neighborhood': 55,\n",
       " 'san': 76,\n",
       " 'francisco': 31,\n",
       " 'safe': 75,\n",
       " 'free': 32,\n",
       " 'parking': 59,\n",
       " 'located': 46,\n",
       " 'geographically': 34,\n",
       " 'center': 17,\n",
       " 'city': 18,\n",
       " 'public': 68,\n",
       " 'available': 10,\n",
       " '15': 1,\n",
       " 'minute': 51,\n",
       " 'private': 67,\n",
       " 'bathroom': 11,\n",
       " 'room': 74,\n",
       " 'street': 83,\n",
       " 'lovely': 48,\n",
       " 'noe': 57,\n",
       " 'valley': 94,\n",
       " 'access': 5,\n",
       " 'muni': 54,\n",
       " 'market': 49,\n",
       " 'perfectly': 63,\n",
       " 'enjoy': 26,\n",
       " 'peaceful': 61,\n",
       " 'environment': 28,\n",
       " 'want': 97,\n",
       " 'close': 20,\n",
       " 'shopping': 81,\n",
       " 'restaurant': 72,\n",
       " 'nightlife': 56,\n",
       " 'block': 14,\n",
       " 'j': 41,\n",
       " 'train': 90,\n",
       " '20m': 3,\n",
       " 'ride': 73,\n",
       " '3': 4,\n",
       " 'mission': 52,\n",
       " 'apartment': 8,\n",
       " '2': 2,\n",
       " 'bedroom': 12,\n",
       " '1': 0,\n",
       " 'recently': 70,\n",
       " 'remodeled': 71,\n",
       " 'modern': 53,\n",
       " 'kitchen': 42,\n",
       " 'dishwasher': 23,\n",
       " 'washerdryer': 98,\n",
       " 'building': 16,\n",
       " 'use': 93,\n",
       " 'best': 13,\n",
       " 'hill': 38,\n",
       " 'climb': 19,\n",
       " 'sunny': 85,\n",
       " 'airy': 6,\n",
       " 'minimalist': 50,\n",
       " 'terrarium': 87,\n",
       " 'various': 95,\n",
       " 'plant': 66,\n",
       " 'scattered': 78,\n",
       " 'entire': 27,\n",
       " 'place': 65,\n",
       " 'including': 40,\n",
       " 'living': 45,\n",
       " 'dining': 22,\n",
       " 'garage': 33,\n",
       " 'love': 47,\n",
       " 'spend': 82,\n",
       " 'time': 88,\n",
       " 'guest': 36,\n",
       " 'listed': 44,\n",
       " 'im': 39,\n",
       " 'town': 89,\n",
       " 'reachable': 69,\n",
       " 'phone': 64,\n",
       " 'anytime': 7,\n",
       " 'offer': 58,\n",
       " 'suggestionsadvice': 84,\n",
       " 'arrive': 9,\n",
       " 'favorite': 29,\n",
       " 'share': 80,\n",
       " 'truly': 92,\n",
       " 'sense': 79,\n",
       " 'community': 21,\n",
       " 'people': 62,\n",
       " 'like': 43,\n",
       " 'say': 77,\n",
       " 'hello': 37,\n",
       " 'passing': 60}"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf_vectorizer_train.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LemmaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split data - running NLP on \"access\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(start_month, end_month):\n",
    "    df_X_train = df_sf_2017[(df_sf_2017['month'] >= start_month) & (df_sf_2017['month'] < end_month)]['space_new']\n",
    "    y_train = df_sf_2017[(df_sf_2017['month'] >= start_month) & (df_sf_2017['month'] < end_month)]['popular']\n",
    "\n",
    "    df_X_test = df_sf_2017[df_sf_2017['month'] == end_month]['space_new']\n",
    "    y_test = df_sf_2017[df_sf_2017['month'] == end_month]['popular']\n",
    "    \n",
    "    return df_X_train, y_train, df_X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 7.15 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def run_tf_vec(df_X_train, df_X_test):\n",
    "    tf_vectorizer_train = CountVectorizer(tokenizer=LemmaTokenizer(), stop_words='english').fit(df_X_train)\n",
    "    X_train = tf_vectorizer_train.transform(df_X_train)\n",
    "    tf_vectorizer_test = CountVectorizer(tokenizer=LemmaTokenizer(), stop_words='english', vocabulary = tf_vectorizer_train.vocabulary_).fit(df_X_test)\n",
    "    X_test = tf_vectorizer_test.transform(df_X_test)\n",
    "    return X_train, X_test, tf_vectorizer_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<26526x12784 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1848230 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tf_nb(X_train, y_train, X_test, y_test):\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train, y_train)\n",
    "    pickle.dump(nb, open('tf_nb_space'+ str(model_num) + '.p', 'wb'))\n",
    "    preds = nb.predict(X_test)\n",
    "    scores_tf_nb[0][model_num] = accuracy_score(y_test, preds)\n",
    "    scores_tf_nb[1][model_num] = recall_score(y_test, nb.predict(X_test))\n",
    "    scores_tf_nb[2][model_num] = precision_score(y_test, nb.predict(X_test))\n",
    "    scores_tf_nb[3][model_num] = f1_score(y_test, nb.predict(X_test))\n",
    "    return scores_tf_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def grid_searching (param_grid, model):\n",
    "\n",
    "#     grid_search = GridSearchCV(model, \n",
    "#                                param_grid=param_grid, cv=5, \n",
    "#                                n_jobs=-1, scoring=make_scorer(f1_score))\n",
    "#     fit = grid_search.fit(X_train, y_train)\n",
    "#     predicted = fit.predict(X_test)\n",
    "#     return grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With the CountVectorizer, run with RandomForest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tf_rf(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators = 500, \n",
    "                                n_jobs = -1, \n",
    "                                random_state = 0, \n",
    "                                max_depth = 10)\n",
    "    rf.fit(X_train, y_train)\n",
    "    predicted = rf.predict(X_test)\n",
    "    pickle.dump(rf, open('tf_rf_space' + str(model_num) + '.p', 'wb'))\n",
    "    scores_tf_rf[0][model_num] = accuracy_score(y_test, predicted)\n",
    "    scores_tf_rf[1][model_num] = recall_score(y_test, predicted)\n",
    "    scores_tf_rf[2][model_num] = precision_score(y_test, predicted)\n",
    "    scores_tf_rf[3][model_num] = f1_score(y_test, predicted)\n",
    "    return scores_tf_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_tf_nb = np.zeros(shape=(4,9))\n",
    "scores_tf_rf = np.zeros(shape=(4,9))\n",
    "\n",
    "model_num = 0\n",
    "start_month = 1\n",
    "end_month = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4 0\n",
      "tf_nb\n",
      "[[0.87317298 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.58568615 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.65443874 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.61815662 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "tf_rf\n",
      "[[0.82759811 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.01838477 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.90322581 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.03603604 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "2 5 1\n",
      "tf_nb\n",
      "[[0.87317298 0.87385321 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.58568615 0.58087754 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.65443874 0.65850037 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.61815662 0.61725818 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "tf_rf\n",
      "[[0.82759811 0.8271789  0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.01838477 0.01440733 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.90322581 0.91666667 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.03603604 0.02836879 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "3 6 2\n",
      "tf_nb\n",
      "[[0.87317298 0.87385321 0.87041676 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.58568615 0.58087754 0.57570093 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.65443874 0.65850037 0.66908038 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.61815662 0.61725818 0.61888814 0.         0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "tf_rf\n",
      "[[0.82759811 0.8271789  0.82008654 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.01838477 0.01440733 0.01619938 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.90322581 0.91666667 0.96296296 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.03603604 0.02836879 0.03186275 0.         0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "4 7 3\n",
      "tf_nb\n",
      "[[0.87317298 0.87385321 0.87041676 0.8712524  0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.58568615 0.58087754 0.57570093 0.57368102 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.65443874 0.65850037 0.66908038 0.68501086 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.61815662 0.61725818 0.61888814 0.62442244 0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "tf_rf\n",
      "[[0.82759811 0.8271789  0.82008654 0.81762643 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.01838477 0.01440733 0.01619938 0.02304427 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.90322581 0.91666667 0.96296296 0.97435897 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.03603604 0.02836879 0.03186275 0.0450237  0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "5 8 4\n",
      "tf_nb\n",
      "[[0.87317298 0.87385321 0.87041676 0.8712524  0.86523567 0.\n",
      "  0.         0.         0.        ]\n",
      " [0.58568615 0.58087754 0.57570093 0.57368102 0.55599325 0.\n",
      "  0.         0.         0.        ]\n",
      " [0.65443874 0.65850037 0.66908038 0.68501086 0.69724771 0.\n",
      "  0.         0.         0.        ]\n",
      " [0.61815662 0.61725818 0.61888814 0.62442244 0.61865999 0.\n",
      "  0.         0.         0.        ]]\n",
      "tf_rf\n",
      "[[0.82759811 0.8271789  0.82008654 0.81762643 0.80659438 0.\n",
      "  0.         0.         0.        ]\n",
      " [0.01838477 0.01440733 0.01619938 0.02304427 0.01744513 0.\n",
      "  0.         0.         0.        ]\n",
      " [0.90322581 0.91666667 0.96296296 0.97435897 0.93939394 0.\n",
      "  0.         0.         0.        ]\n",
      " [0.03603604 0.02836879 0.03186275 0.0450237  0.03425414 0.\n",
      "  0.         0.         0.        ]]\n",
      "6 9 5\n",
      "tf_nb\n",
      "[[0.87317298 0.87385321 0.87041676 0.8712524  0.86523567 0.8564211\n",
      "  0.         0.         0.        ]\n",
      " [0.58568615 0.58087754 0.57570093 0.57368102 0.55599325 0.55155211\n",
      "  0.         0.         0.        ]\n",
      " [0.65443874 0.65850037 0.66908038 0.68501086 0.69724771 0.70667614\n",
      "  0.         0.         0.        ]\n",
      " [0.61815662 0.61725818 0.61888814 0.62442244 0.61865999 0.61955168\n",
      "  0.         0.         0.        ]]\n",
      "tf_rf\n",
      "[[0.82759811 0.8271789  0.82008654 0.81762643 0.80659438 0.79179885\n",
      "  0.         0.         0.        ]\n",
      " [0.01838477 0.01440733 0.01619938 0.02304427 0.01744513 0.01884701\n",
      "  0.         0.         0.        ]\n",
      " [0.90322581 0.91666667 0.96296296 0.97435897 0.93939394 0.94444444\n",
      "  0.         0.         0.        ]\n",
      " [0.03603604 0.02836879 0.03186275 0.0450237  0.03425414 0.03695652\n",
      "  0.         0.         0.        ]]\n",
      "7 10 6\n",
      "tf_nb\n",
      "[[0.87317298 0.87385321 0.87041676 0.8712524  0.86523567 0.8564211\n",
      "  0.85945581 0.         0.        ]\n",
      " [0.58568615 0.58087754 0.57570093 0.57368102 0.55599325 0.55155211\n",
      "  0.56512141 0.         0.        ]\n",
      " [0.65443874 0.65850037 0.66908038 0.68501086 0.69724771 0.70667614\n",
      "  0.68909825 0.         0.        ]\n",
      " [0.61815662 0.61725818 0.61888814 0.62442244 0.61865999 0.61955168\n",
      "  0.62098241 0.         0.        ]]\n",
      "tf_rf\n",
      "[[0.82759811 0.8271789  0.82008654 0.81762643 0.80659438 0.79179885\n",
      "  0.80008995 0.         0.        ]\n",
      " [0.01838477 0.01440733 0.01619938 0.02304427 0.01744513 0.01884701\n",
      "  0.01931567 0.         0.        ]\n",
      " [0.90322581 0.91666667 0.96296296 0.97435897 0.93939394 0.94444444\n",
      "  0.97222222 0.         0.        ]\n",
      " [0.03603604 0.02836879 0.03186275 0.0450237  0.03425414 0.03695652\n",
      "  0.03787879 0.         0.        ]]\n",
      "8 11 7\n",
      "tf_nb\n",
      "[[0.87317298 0.87385321 0.87041676 0.8712524  0.86523567 0.8564211\n",
      "  0.85945581 0.84773479 0.        ]\n",
      " [0.58568615 0.58087754 0.57570093 0.57368102 0.55599325 0.55155211\n",
      "  0.56512141 0.58966565 0.        ]\n",
      " [0.65443874 0.65850037 0.66908038 0.68501086 0.69724771 0.70667614\n",
      "  0.68909825 0.70151216 0.        ]\n",
      " [0.61815662 0.61725818 0.61888814 0.62442244 0.61865999 0.61955168\n",
      "  0.62098241 0.64074463 0.        ]]\n",
      "tf_rf\n",
      "[[0.82759811 0.8271789  0.82008654 0.81762643 0.80659438 0.79179885\n",
      "  0.80008995 0.77411555 0.        ]\n",
      " [0.01838477 0.01440733 0.01619938 0.02304427 0.01744513 0.01884701\n",
      "  0.01931567 0.01961868 0.        ]\n",
      " [0.90322581 0.91666667 0.96296296 0.97435897 0.93939394 0.94444444\n",
      "  0.97222222 0.97260274 0.        ]\n",
      " [0.03603604 0.02836879 0.03186275 0.0450237  0.03425414 0.03695652\n",
      "  0.03787879 0.03846154 0.        ]]\n",
      "9 12 8\n",
      "tf_nb\n",
      "[[0.87317298 0.87385321 0.87041676 0.8712524  0.86523567 0.8564211\n",
      "  0.85945581 0.84773479 0.83353204]\n",
      " [0.58568615 0.58087754 0.57570093 0.57368102 0.55599325 0.55155211\n",
      "  0.56512141 0.58966565 0.63366906]\n",
      " [0.65443874 0.65850037 0.66908038 0.68501086 0.69724771 0.70667614\n",
      "  0.68909825 0.70151216 0.69617452]\n",
      " [0.61815662 0.61725818 0.61888814 0.62442244 0.61865999 0.61955168\n",
      "  0.62098241 0.64074463 0.66345285]]\n",
      "tf_rf\n",
      "[[0.82759811 0.8271789  0.82008654 0.81762643 0.80659438 0.79179885\n",
      "  0.80008995 0.77411555 0.74806259]\n",
      " [0.01838477 0.01440733 0.01619938 0.02304427 0.01744513 0.01884701\n",
      "  0.01931567 0.01961868 0.0276259 ]\n",
      " [0.90322581 0.91666667 0.96296296 0.97435897 0.93939394 0.94444444\n",
      "  0.97222222 0.97260274 0.97959184]\n",
      " [0.03603604 0.02836879 0.03186275 0.0450237  0.03425414 0.03695652\n",
      "  0.03787879 0.03846154 0.05373636]]\n",
      "CPU times: user 9min 25s, sys: 660 ms, total: 9min 25s\n",
      "Wall time: 8min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "while end_month <13:\n",
    "    df_X_train, y_train, df_X_test, y_test = split_data(start_month, end_month)\n",
    "    X_train, X_test, tf_vectorizer_train = run_tf_vec(df_X_train, df_X_test)\n",
    "    scores_tf_nb = predict_tf_nb(X_train, y_train, X_test, y_test)\n",
    "    scores_tf_rf = predict_tf_rf(X_train, y_train, X_test, y_test)\n",
    "    print(start_month, end_month, model_num)\n",
    "    model_num += 1\n",
    "    start_month += 1\n",
    "    end_month += 1\n",
    "    print('tf_nb')\n",
    "    print(scores_tf_nb)\n",
    "    print('tf_rf')\n",
    "    print(scores_tf_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COUNT VECTORIZER NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8612305305476693\n",
      "0.579105235702455\n",
      "0.6841932357268582\n",
      "0.6269018826966994\n"
     ]
    }
   ],
   "source": [
    "accuracy_2017_tf_nb = np.mean(scores_tf_nb[0])\n",
    "recall_2017_tf_nb = np.mean(scores_tf_nb[1])\n",
    "precision_2017_tf_nb = np.mean(scores_tf_nb[2])\n",
    "f1_score_2017_tf_nb = np.mean(scores_tf_nb[3])\n",
    "print(accuracy_2017_tf_nb)\n",
    "print(recall_2017_tf_nb)\n",
    "print(precision_2017_tf_nb)\n",
    "print(f1_score_2017_tf_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COUNT VECTORIZER RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8014612556567209\n",
      "0.019432015379088063\n",
      "0.9517188436623937\n",
      "0.03806429109688944\n"
     ]
    }
   ],
   "source": [
    "accuracy_2017_tf_rf = np.mean(scores_tf_rf[0])\n",
    "recall_2017_tf_rf = np.mean(scores_tf_rf[1])\n",
    "precision_2017_tf_rf = np.mean(scores_tf_rf[2])\n",
    "f1_score_2017_tf_rf = np.mean(scores_tf_rf[3])\n",
    "print(accuracy_2017_tf_rf)\n",
    "print(recall_2017_tf_rf)\n",
    "print(precision_2017_tf_rf)\n",
    "print(f1_score_2017_tf_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try running with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tf_idf_vec(df_X_train, df_X_test):\n",
    "    tf_idf_vectorizer_train = TfidfVectorizer(tokenizer=LemmaTokenizer(), stop_words='english')\n",
    "    X_train = tf_idf_vectorizer_train.fit_transform(df_X_train).toarray()\n",
    "    tf_idf_vectorizer_test = TfidfVectorizer(tokenizer=LemmaTokenizer(), stop_words='english', vocabulary = tf_idf_vectorizer_train.vocabulary_)\n",
    "    X_test = tf_idf_vectorizer_test.fit_transform(df_X_test).toarray()\n",
    "    return X_train, X_test, tf_idf_vectorizer_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tf_idf_nb(X_train, y_train, X_test, y_test):\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    nb = GaussianNB()\n",
    "    nb.fit(X_train, y_train)\n",
    "    pickle.dump(nb, open('tf_idf_nb_space.p', 'wb'))\n",
    "    preds = nb.predict(X_test2)\n",
    "    scores_tf_idf_nb[0][model_num] = accuracy_score(y_test, preds)\n",
    "    scores_tf_idf_nb[1][model_num] = recall_score(y_test, preds)\n",
    "    scores_tf_idf_nb[2][model_num] = precision_score(y_test, preds)\n",
    "    scores_tf_idf_nb[3][model_num] = f1_score(y_test, preds)\n",
    "    return scores_tf_idf_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With the TF-IDF, run with RandomForest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tf_idf_rf(X_train, y_train, X_test, y_test):\n",
    "    rf = RandomForestClassifier(n_estimators = 10, n_jobs=-1, random_state=0, class_weight = {0:.95, 1:.05})\n",
    "    rf.fit(X_train, y_train)\n",
    "    predicted = rf.predict(X_test2)\n",
    "    pickle.dump(rf, open('tf_idf_rf_space', 'wb'))\n",
    "    scores_tf_idf_rf[0][model_num] = accuracy_score(y_test, predicted)\n",
    "    scores_tf_idf_rf[1][model_num] = recall_score(y_test, predicted)\n",
    "    scores_tf_idf_rf[2][model_num] = precision_score(y_test, predicted)\n",
    "    scores_tf_idf_rf[3][model_num] = f1_score(y_test, predicted)\n",
    "    return scores_tf_idf_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_tf_idf_nb = np.zeros(shape=(4,9))\n",
    "scores_tf_idf_rf = np.zeros(shape=(4,9))\n",
    "\n",
    "model_num = 0\n",
    "start_month = 1\n",
    "end_month = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4 0\n",
      "tf_idf_nb\n",
      "[[0.52802394 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.95994747 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.26572156 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.41622776 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "tf_idf_rf\n",
      "[[0.93566578 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.67826658 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.93738657 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.78704762 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "2 5 1\n",
      "tf_idf_nb\n",
      "[[0.52802394 0.52144495 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.95994747 0.94826457 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.26572156 0.26127752 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.41622776 0.40967605 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "tf_idf_rf\n",
      "[[0.93566578 0.93222477 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.67826658 0.65553373 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.93738657 0.93902439 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.78704762 0.77207867 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "3 6 2\n",
      "tf_idf_nb\n",
      "[[0.52802394 0.52144495 0.52983375 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.95994747 0.94826457 0.95264798 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.26572156 0.26127752 0.27391616 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.41622776 0.40967605 0.42549047 0.         0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "tf_idf_rf\n",
      "[[0.93566578 0.93222477 0.92871783 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.67826658 0.65553373 0.6623053  0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.93738657 0.93902439 0.92676548 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.78704762 0.77207867 0.77252907 0.         0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "4 7 3\n",
      "tf_idf_nb\n",
      "[[0.52802394 0.52144495 0.52983375 0.53377079 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.95994747 0.94826457 0.95264798 0.95209218 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.26572156 0.26127752 0.27391616 0.27975766 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.41622776 0.40967605 0.42549047 0.43244732 0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "tf_idf_rf\n",
      "[[0.93566578 0.93222477 0.92871783 0.9311008  0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.67826658 0.65553373 0.6623053  0.67252881 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.93738657 0.93902439 0.92676548 0.94142615 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.78704762 0.77207867 0.77252907 0.78457729 0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "5 8 4\n",
      "tf_idf_nb\n",
      "[[0.52802394 0.52144495 0.52983375 0.53377079 0.53518478 0.\n",
      "  0.         0.         0.        ]\n",
      " [0.95994747 0.94826457 0.95264798 0.95209218 0.9414744  0.\n",
      "  0.         0.         0.        ]\n",
      " [0.26572156 0.26127752 0.27391616 0.27975766 0.28994801 0.\n",
      "  0.         0.         0.        ]\n",
      " [0.41622776 0.40967605 0.42549047 0.43244732 0.44335498 0.\n",
      "  0.         0.         0.        ]]\n",
      "tf_idf_rf\n",
      "[[0.93566578 0.93222477 0.92871783 0.9311008  0.91734897 0.\n",
      "  0.         0.         0.        ]\n",
      " [0.67826658 0.65553373 0.6623053  0.67252881 0.61902082 0.\n",
      "  0.         0.         0.        ]\n",
      " [0.93738657 0.93902439 0.92676548 0.94142615 0.94017094 0.\n",
      "  0.         0.         0.        ]\n",
      " [0.78704762 0.77207867 0.77252907 0.78457729 0.74652189 0.\n",
      "  0.         0.         0.        ]]\n",
      "6 9 5\n",
      "tf_idf_nb\n",
      "[[0.52802394 0.52144495 0.52983375 0.53377079 0.53518478 0.55645635\n",
      "  0.         0.         0.        ]\n",
      " [0.95994747 0.94826457 0.95264798 0.95209218 0.9414744  0.96230599\n",
      "  0.         0.         0.        ]\n",
      " [0.26572156 0.26127752 0.27391616 0.27975766 0.28994801 0.31894176\n",
      "  0.         0.         0.        ]\n",
      " [0.41622776 0.40967605 0.42549047 0.43244732 0.44335498 0.4790948\n",
      "  0.         0.         0.        ]]\n",
      "tf_idf_rf\n",
      "[[0.93566578 0.93222477 0.92871783 0.9311008  0.91734897 0.91928093\n",
      "  0.         0.         0.        ]\n",
      " [0.67826658 0.65553373 0.6623053  0.67252881 0.61902082 0.64190687\n",
      "  0.         0.         0.        ]\n",
      " [0.93738657 0.93902439 0.92676548 0.94142615 0.94017094 0.96580484\n",
      "  0.         0.         0.        ]\n",
      " [0.78704762 0.77207867 0.77252907 0.78457729 0.74652189 0.77122877\n",
      "  0.         0.         0.        ]]\n",
      "7 10 6\n",
      "tf_idf_nb\n",
      "[[0.52802394 0.52144495 0.52983375 0.53377079 0.53518478 0.55645635\n",
      "  0.53946481 0.         0.        ]\n",
      " [0.95994747 0.94826457 0.95264798 0.95209218 0.9414744  0.96230599\n",
      "  0.95584989 0.         0.        ]\n",
      " [0.26572156 0.26127752 0.27391616 0.27975766 0.28994801 0.31894176\n",
      "  0.3013222  0.         0.        ]\n",
      " [0.41622776 0.40967605 0.42549047 0.43244732 0.44335498 0.4790948\n",
      "  0.45820106 0.         0.        ]]\n",
      "tf_idf_rf\n",
      "[[0.93566578 0.93222477 0.92871783 0.9311008  0.91734897 0.91928093\n",
      "  0.91882168 0.         0.        ]\n",
      " [0.67826658 0.65553373 0.6623053  0.67252881 0.61902082 0.64190687\n",
      "  0.65011038 0.         0.        ]\n",
      " [0.93738657 0.93902439 0.92676548 0.94142615 0.94017094 0.96580484\n",
      "  0.93048973 0.         0.        ]\n",
      " [0.78704762 0.77207867 0.77252907 0.78457729 0.74652189 0.77122877\n",
      "  0.7654321  0.         0.        ]]\n",
      "8 11 7\n",
      "tf_idf_nb\n",
      "[[0.52802394 0.52144495 0.52983375 0.53377079 0.53518478 0.55645635\n",
      "  0.53946481 0.56916518 0.        ]\n",
      " [0.95994747 0.94826457 0.95264798 0.95209218 0.9414744  0.96230599\n",
      "  0.95584989 0.95965736 0.        ]\n",
      " [0.26572156 0.26127752 0.27391616 0.27975766 0.28994801 0.31894176\n",
      "  0.3013222  0.34392949 0.        ]\n",
      " [0.41622776 0.40967605 0.42549047 0.43244732 0.44335498 0.4790948\n",
      "  0.45820106 0.50637895 0.        ]]\n",
      "tf_idf_rf\n",
      "[[0.93566578 0.93222477 0.92871783 0.9311008  0.91734897 0.91928093\n",
      "  0.91882168 0.92065411 0.        ]\n",
      " [0.67826658 0.65553373 0.6623053  0.67252881 0.61902082 0.64190687\n",
      "  0.65011038 0.69798287 0.        ]\n",
      " [0.93738657 0.93902439 0.92676548 0.94142615 0.94017094 0.96580484\n",
      "  0.93048973 0.94253731 0.        ]\n",
      " [0.78704762 0.77207867 0.77252907 0.78457729 0.74652189 0.77122877\n",
      "  0.7654321  0.80203207 0.        ]]\n",
      "9 12 8\n",
      "tf_idf_nb\n",
      "[[0.52802394 0.52144495 0.52983375 0.53377079 0.53518478 0.55645635\n",
      "  0.53946481 0.56916518 0.59992548]\n",
      " [0.95994747 0.94826457 0.95264798 0.95209218 0.9414744  0.96230599\n",
      "  0.95584989 0.95965736 0.96517986]\n",
      " [0.26572156 0.26127752 0.27391616 0.27975766 0.28994801 0.31894176\n",
      "  0.3013222  0.34392949 0.38990932]\n",
      " [0.41622776 0.40967605 0.42549047 0.43244732 0.44335498 0.4790948\n",
      "  0.45820106 0.50637895 0.55543595]]\n",
      "tf_idf_rf\n",
      "[[0.93566578 0.93222477 0.92871783 0.9311008  0.91734897 0.91928093\n",
      "  0.91882168 0.92065411 0.91788376]\n",
      " [0.67826658 0.65553373 0.6623053  0.67252881 0.61902082 0.64190687\n",
      "  0.65011038 0.69798287 0.73467626]\n",
      " [0.93738657 0.93902439 0.92676548 0.94142615 0.94017094 0.96580484\n",
      "  0.93048973 0.94253731 0.93413831]\n",
      " [0.78704762 0.77207867 0.77252907 0.78457729 0.74652189 0.77122877\n",
      "  0.7654321  0.80203207 0.82248711]]\n",
      "CPU times: user 1h 9min 41s, sys: 36.2 s, total: 1h 10min 18s\n",
      "Wall time: 19min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "while end_month <13:\n",
    "    df_X_train, y_train, df_X_test, y_test = split_data(start_month, end_month) \n",
    "    X_train2, X_test2, tf_idf_vectorizer_train = run_tf_idf_vec(df_X_train, df_X_test)\n",
    "    scores_tf_idf_nb = predict_tf_idf_nb(X_train2, y_train, X_test2, y_test)\n",
    "    scores_tf_idf_rf = predict_tf_idf_rf(X_train2, y_train, X_test2, y_test)\n",
    "    print(start_month, end_month, model_num)\n",
    "    model_num += 1\n",
    "    start_month += 1\n",
    "    end_month += 1\n",
    "    print('tf_idf_nb')\n",
    "    print(scores_tf_idf_nb)\n",
    "    print('tf_idf_rf')\n",
    "    print(scores_tf_idf_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF IDF NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5459188924345899\n",
      "0.9552688540778203\n",
      "0.3027470749548262\n",
      "0.45847859206465674\n"
     ]
    }
   ],
   "source": [
    "accuracy_2017_tf_idf_nb = np.mean(scores_tf_idf_nb[0])\n",
    "recall_2017_tf_idf_nb = np.mean(scores_tf_idf_nb[1])\n",
    "precision_2017_tf_idf_nb = np.mean(scores_tf_idf_nb[2])\n",
    "f1_score_2017_tf_idf_nb = np.mean(scores_tf_idf_nb[3])\n",
    "print(accuracy_2017_tf_idf_nb)\n",
    "print(recall_2017_tf_idf_nb)\n",
    "print(precision_2017_tf_idf_nb)\n",
    "print(f1_score_2017_tf_idf_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF IDF RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9246331817012164\n",
      "0.6680368449283941\n",
      "0.939749301470601\n",
      "0.7804371768025824\n"
     ]
    }
   ],
   "source": [
    "accuracy_2017_tf_idf_rf = np.mean(scores_tf_idf_rf[0])\n",
    "recall_2017_tf_idf_rf = np.mean(scores_tf_idf_rf[1])\n",
    "precision_2017_tf_idf_rf = np.mean(scores_tf_idf_rf[2])\n",
    "f1_score_2017_tf_idf_rf = np.mean(scores_tf_idf_rf[3])\n",
    "print(accuracy_2017_tf_idf_rf)\n",
    "print(recall_2017_tf_idf_rf)\n",
    "print(precision_2017_tf_idf_rf)\n",
    "print(f1_score_2017_tf_idf_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# from collections import Counter\n",
    "# from scipy.spatial.distance import pdist, squareform\n",
    "# from scipy.cluster.hierarchy import linkage, dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features =  tf_idf_vectorizer_train.get_feature_names()\n",
    "\n",
    "# start_month = 1\n",
    "# end_month = 4\n",
    "# df_X_train = df_sf_2017[(df_sf_2017['month'] >= start_month) & (df_sf_2017['month'] < end_month)]['space_new']\n",
    "# y_train = df_sf_2017[(df_sf_2017['month'] >= start_month) & (df_sf_2017['month'] < end_month)]['popular']\n",
    "\n",
    "# df_X_test = df_sf_2017[df_sf_2017['month'] == end_month]['space_new']\n",
    "# y_test = df_sf_2017[df_sf_2017['month'] == end_month]['popular']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1300',\n",
       " '1300sqft',\n",
       " '1304',\n",
       " '1315',\n",
       " '132',\n",
       " '135',\n",
       " '1350',\n",
       " '135cm',\n",
       " '136',\n",
       " '137',\n",
       " '1370123',\n",
       " '13724120',\n",
       " '139',\n",
       " '1394',\n",
       " '1396',\n",
       " '13ft',\n",
       " '13in',\n",
       " '13lb',\n",
       " '13mn',\n",
       " '13th',\n",
       " '13x12',\n",
       " '14',\n",
       " '140',\n",
       " '1400',\n",
       " '1400ft²',\n",
       " '1400sf',\n",
       " '1408',\n",
       " '140sq',\n",
       " '140sqm',\n",
       " '14154147',\n",
       " '143',\n",
       " '144',\n",
       " '145',\n",
       " '1450',\n",
       " '14611926',\n",
       " '1474',\n",
       " '149',\n",
       " '14ft',\n",
       " '14l',\n",
       " '14min',\n",
       " '14r',\n",
       " '14sqm',\n",
       " '14th',\n",
       " '14x',\n",
       " '14x12',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '1500ft',\n",
       " '1500sf']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features[150:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 17s, sys: 3.51 s, total: 1min 20s\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# kmeans = KMeans(n_clusters=2, n_jobs=-1)\n",
    "# kmeans.fit(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top features (words) for each cluster:\n",
      "0: san, apartment, block, francisco, street, place, restaurant, neighborhood, park, kitchen, room, city, bedroom, walk, located, access, home, close, great, bed, ha, away, private, view, location, mission, space, sf, minute, 2, walking, bathroom, downtown, area, parking, house, bar, floor, distance, bus, bart, quiet, gate, easy, guest, available, district, public, golden, building, stay, 1, square, shop, just, unit, heart, youll, beautiful\n",
      "1: room, bedroom, bed, kitchen, ha, bathroom, living, private, home, san, apartment, large, 2, access, francisco, house, floor, guest, street, queen, block, space, park, area, neighborhood, located, view, 1, city, restaurant, great, tv, parking, dining, quiet, walk, spacious, available, bath, shared, away, flat, beautiful, comfortable, sf, mission, garden, place, stay, size, 3, downtown, open, deck, easy, just, unit, close, new\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 2.05 ms\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# # TF vectorizer\n",
    "# top_centroids = kmeans.cluster_centers_.argsort()[:,-1:-60:-1]\n",
    "# print(\"top features (words) for each cluster:\")\n",
    "# for num, centroid in enumerate(top_centroids):\n",
    "#     print(\"%d: %s\" % (num, \", \".join(features[i] for i in centroid)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top features (words) for each cluster:\n",
      "0: space, home, house, city, san, place, great, view, francisco, apartment, room, location, quiet, light, sf, floor, comfortable, ha, neighborhood, lot, close, restaurant, clean, unit, street, guest, beautiful, time, studio, park, modern, building, stay, feel, wa, like, kitchen, perfect, people, cozy, art, need, block, bed, unique, new, located, available, just\n",
      "1: room, bedroom, bed, ha, kitchen, bathroom, living, private, apartment, large, floor, space, san, queen, home, 2, francisco, house, street, area, guest, tv, view, block, access, size, great, located, 1, city, comfortable, neighborhood, dining, park, spacious, bath, parking, flat, new, unit, quiet, away, closet, garden, window, walk, beautiful, coffee, available\n",
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 2.92 ms\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# # TF-IDF vectorizer\n",
    "# top_centroids = kmeans.cluster_centers_.argsort()[:,-1:-50:-1]\n",
    "# print(\"top features (words) for each cluster:\")\n",
    "# for num, centroid in enumerate(top_centroids):\n",
    "#     print(\"%d: %s\" % (num, \", \".join(features[i] for i in centroid)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def catPred(kmObj, gTrue, pred): \n",
    "#     '''\n",
    "#         kmObjn: a kmeans object\n",
    "#         gTrue: true categories (ground truth)\n",
    "#     '''\n",
    "#     fig, ax = plt.subplots(nrows=1, ncols=2, sharey=True, figsize=(50,12))\n",
    "\n",
    "#     numClusters = kmObj.get_params()['n_clusters']\n",
    "    \n",
    "#     for i in range(numClusters):\n",
    "#         print(i)\n",
    "#         mask = (pred == i)\n",
    "#         val = np.unique(gTrue[mask], return_counts=True)\n",
    "#         lbl = val[0]\n",
    "#         ht  = val[1] / val[1].sum()\n",
    "#         ax[i].bar(range(numClusters), height=ht, tick_label = lbl)\n",
    "#         ax[i].set_xticklabels(lbl, fontsize=20)\n",
    "#         ax[i].set_title(i, fontsize=20)\n",
    "\n",
    "#         ax[0].set_yticklabels([\"0\", \"0.2\", \"0.4\", \"0.6\", \"0.8\"], fontsize=20)\n",
    "#         ax[0].set_ylabel(\"Proportion\", fontsize = 32);\n",
    "#         plt.suptitle(\"Proportion of Categories in each Cluster\", fontsize = 32);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-5afe2d70811e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcatPred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'preds' is not defined"
     ]
    }
   ],
   "source": [
    "# catPred(kmeans, y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kmeans.get_params()['n_clusters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
