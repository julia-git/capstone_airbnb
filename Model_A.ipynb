{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP on description column, Random Forest was the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, make_scorer, precision_score, f1_score\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\",999)\n",
    "pd.set_option(\"display.max_rows\",999)\n",
    "pd.set_option(\"display.max_columns\",999)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sf_2017 = pd.read_json('df_sf_2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sf_2017.description.fillna(value='None', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sf_2017[\"description_new\"] = df_sf_2017['description'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LemmaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split data - running NLP on description column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(start_month, end_month):\n",
    "    df_X_train = df_sf_2017[(df_sf_2017['month'] >= start_month) & (df_sf_2017['month'] < end_month)]['description_new']\n",
    "    y_train = df_sf_2017[(df_sf_2017['month'] >= start_month) & (df_sf_2017['month'] < end_month)]['popular']\n",
    "\n",
    "    df_X_test = df_sf_2017[df_sf_2017['month'] == end_month]['description_new']\n",
    "    y_test = df_sf_2017[df_sf_2017['month'] == end_month]['popular']\n",
    "    \n",
    "    return df_X_train, y_train, df_X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tf_vec(df_X_train, df_X_test, model_num):\n",
    "    tf_vectorizer_train = CountVectorizer(tokenizer=LemmaTokenizer(), stop_words='english').fit(df_X_train)\n",
    "    X_train = tf_vectorizer_train.transform(df_X_train)\n",
    "    \n",
    "    tf_vectorizer_test = CountVectorizer(tokenizer=LemmaTokenizer(), stop_words='english', vocabulary = tf_vectorizer_train.vocabulary_).fit(df_X_test)\n",
    "    X_test = tf_vectorizer_test.transform(df_X_test)\n",
    "    \n",
    "    pickle.dump(tf_vectorizer_test, open('tf_vec_descrip'+ str(model_num) + '.p', 'wb'))\n",
    "    \n",
    "    return X_train, X_test, tf_vectorizer_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<26498x20903 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1649921 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tf_nb(X_train, y_train, X_test, y_test):\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train, y_train)\n",
    "    pickle.dump(nb, open('tf_nb_descrip'+ str(model_num) + '.p', 'wb'))\n",
    "    preds = nb.predict(X_test)\n",
    "    scores_tf_nb[0][model_num] = accuracy_score(y_test, preds)\n",
    "    scores_tf_nb[1][model_num] = recall_score(y_test, nb.predict(X_test))\n",
    "    scores_tf_nb[2][model_num] = precision_score(y_test, nb.predict(X_test))\n",
    "    scores_tf_nb[3][model_num] = f1_score(y_test, nb.predict(X_test))\n",
    "    return scores_tf_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_searching (param_grid, model):\n",
    "\n",
    "    grid_search = GridSearchCV(model, \n",
    "                               param_grid=param_grid, cv=5, \n",
    "                               n_jobs=-1, scoring=make_scorer(f1_score))\n",
    "    fit = grid_search.fit(X_train, y_train)\n",
    "    predicted = fit.predict(X_test)\n",
    "    return grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With the CountVectorizer, run with RandomForest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tf_rf(X_train, y_train, X_test, y_test):\n",
    "    param_grid = {'n_estimators': [500, 1000], \n",
    "                  'class_weight': [None, {0: .8, 1: .2}, {0: .9, 1: .1}]}\n",
    "\n",
    "    model = RandomForestClassifier()\n",
    "    \n",
    "    best_parameters = grid_searching(param_grid, model)\n",
    "    print(best_parameters)\n",
    "    rf = RandomForestClassifier(n_estimators = best_parameters['n_estimators'], \n",
    "                                n_jobs = -1, \n",
    "                                random_state = 0, \n",
    "                                class_weight = best_parameters['class_weight'])\n",
    "    \n",
    "#     rf = RandomForestClassifier(n_estimators = 500, \n",
    "#                                 n_jobs = -1, \n",
    "#                                 random_state = 0, \n",
    "#                                 max_depth = None, \n",
    "#                                 class_weight = {0: .9, 1: .1})\n",
    "    \n",
    "    \n",
    "    rf.fit(X_train, y_train)\n",
    "    predicted = rf.predict(X_test)\n",
    "#     pickle.dump(rf, open('tf_rf_descrip' + str(model_num) + '.p', 'wb'))\n",
    "    scores_tf_rf[0][model_num] = accuracy_score(y_test, predicted)\n",
    "    scores_tf_rf[1][model_num] = recall_score(y_test, predicted)\n",
    "    scores_tf_rf[2][model_num] = precision_score(y_test, predicted)\n",
    "    scores_tf_rf[3][model_num] = f1_score(y_test, predicted)\n",
    "    return scores_tf_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_tf_nb = np.zeros(shape=(4,9))\n",
    "scores_tf_rf = np.zeros(shape=(4,9))\n",
    "\n",
    "model_num = 0\n",
    "start_month = 1\n",
    "end_month = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': None, 'n_estimators': 500}\n",
      "1 4 0\n",
      "tf_nb\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "tf_rf\n",
      "[[0.96179077 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.85292186 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.92324094 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.88668942 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "{'class_weight': None, 'n_estimators': 500}\n",
      "2 5 1\n",
      "tf_nb\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "tf_rf\n",
      "[[0.96179077 0.96020642 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.85292186 0.82776686 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.92324094 0.93768546 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.88668942 0.87930435 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "{'class_weight': None, 'n_estimators': 500}\n",
      "3 6 2\n",
      "tf_nb\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "tf_rf\n",
      "[[0.96179077 0.96020642 0.95980414 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.85292186 0.82776686 0.83676012 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.92324094 0.93768546 0.93654114 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.88668942 0.87930435 0.88384337 0.         0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "{'class_weight': None, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "while end_month <13:\n",
    "    df_X_train, y_train, df_X_test, y_test = split_data(start_month, end_month)\n",
    "    X_train, X_test, tf_vectorizer_train = run_tf_vec(df_X_train, df_X_test, model_num)\n",
    "#     scores_tf_nb = predict_tf_nb(X_train, y_train, X_test, y_test)\n",
    "    scores_tf_rf = predict_tf_rf(X_train, y_train, X_test, y_test)\n",
    "    print(start_month, end_month, model_num)\n",
    "    model_num += 1\n",
    "    start_month += 1\n",
    "    end_month += 1\n",
    "    print('tf_nb')\n",
    "    print(scores_tf_nb)\n",
    "    print('tf_rf')\n",
    "    print(scores_tf_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': None, 'max_depth': None, 'n_estimators': 1000}\n",
      "1 4 0\n",
      "tf_nb\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "tf_rf\n",
      "[[0.96121533 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.84701248 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.92539455 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.88447035 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': None, 'max_depth': None, 'n_estimators': 500}\n",
      "2 5 1\n",
      "tf_nb\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "tf_rf\n",
      "[[0.96121533 0.96020642 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.84701248 0.82776686 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.92539455 0.93768546 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.88447035 0.87930435 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "{'class_weight': None, 'max_depth': None, 'n_estimators': 500}\n",
      "3 6 2\n",
      "tf_nb\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "tf_rf\n",
      "[[0.96121533 0.96020642 0.95980414 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.84701248 0.82776686 0.83676012 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.92539455 0.93768546 0.93654114 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.88447035 0.87930435 0.88384337 0.         0.         0.\n",
      "  0.         0.         0.        ]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-9d5a30cfc94d>\u001b[0m in \u001b[0;36mpredict_tf_rf\u001b[0;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mbest_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_searching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     rf = RandomForestClassifier(n_estimators = best_parameters['n_estimators'], \n",
      "\u001b[0;32m<ipython-input-51-34594a1d5395>\u001b[0m in \u001b[0;36mgrid_searching\u001b[0;34m(param_grid, model)\u001b[0m\n\u001b[1;32m      4\u001b[0m                                \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                n_jobs=-1, scoring=make_scorer(f1_score))\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "while end_month <13:\n",
    "    df_X_train, y_train, df_X_test, y_test = split_data(start_month, end_month)\n",
    "    X_train, X_test, tf_vectorizer_train = run_tf_vec(df_X_train, df_X_test, model_num)\n",
    "#     scores_tf_nb = predict_tf_nb(X_train, y_train, X_test, y_test)\n",
    "    scores_tf_rf = predict_tf_rf(X_train, y_train, X_test, y_test)\n",
    "    print(start_month, end_month, model_num)\n",
    "    model_num += 1\n",
    "    start_month += 1\n",
    "    end_month += 1\n",
    "    print('tf_nb')\n",
    "    print(scores_tf_nb)\n",
    "    print('tf_rf')\n",
    "    print(scores_tf_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COUNT VECTORIZER NAIVE BAYES SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8742970560045102\n",
      "0.7169107075713074\n",
      "0.6929862495075171\n",
      "0.7043799660889926\n"
     ]
    }
   ],
   "source": [
    "accuracy_2017_tf_nb = np.mean(scores_tf_nb[0])\n",
    "recall_2017_tf_nb = np.mean(scores_tf_nb[1])\n",
    "precision_2017_tf_nb = np.mean(scores_tf_nb[2])\n",
    "f1_score_2017_tf_nb = np.mean(scores_tf_nb[3])\n",
    "print(accuracy_2017_tf_nb)\n",
    "print(recall_2017_tf_nb)\n",
    "print(precision_2017_tf_nb)\n",
    "print(f1_score_2017_tf_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COUNT VECTORIZER RANDOM FOREST SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9474790730435897\n",
      "0.790758536328864\n",
      "0.9494687554573628\n",
      "0.8623895527424829\n"
     ]
    }
   ],
   "source": [
    "accuracy_2017_tf_rf = np.mean(scores_tf_rf[0])\n",
    "recall_2017_tf_rf = np.mean(scores_tf_rf[1])\n",
    "precision_2017_tf_rf = np.mean(scores_tf_rf[2])\n",
    "f1_score_2017_tf_rf = np.mean(scores_tf_rf[3])\n",
    "print(accuracy_2017_tf_rf)\n",
    "print(recall_2017_tf_rf)\n",
    "print(precision_2017_tf_rf)\n",
    "print(f1_score_2017_tf_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try running with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tf_idf_vec(df_X_train, df_X_test):\n",
    "    tf_idf_vectorizer_train = TfidfVectorizer(tokenizer=LemmaTokenizer(), stop_words='english')\n",
    "    X_train2 = tf_idf_vectorizer_train.fit_transform(df_X_train).toarray()\n",
    "    tf_idf_vectorizer_test = TfidfVectorizer(tokenizer=LemmaTokenizer(), stop_words='english', vocabulary = tf_idf_vectorizer_train.vocabulary_)\n",
    "    X_test2 = tf_idf_vectorizer_test.fit_transform(df_X_test).toarray()\n",
    "    return X_train2, X_test2, tf_idf_vectorizer_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tf_idf_nb(X_train2, y_train, X_test2, y_test):\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    nb = GaussianNB()\n",
    "    nb.fit(X_train2, y_train)\n",
    "    pickle.dump(nb, open('tf_idf_nb_descrip' + str(model_num) + '.p', 'wb'))\n",
    "    preds = nb.predict(X_test2)\n",
    "    scores_tf_idf_nb[0][model_num] = accuracy_score(y_test, preds)\n",
    "    scores_tf_idf_nb[1][model_num] = recall_score(y_test, preds)\n",
    "    scores_tf_idf_nb[2][model_num] = precision_score(y_test, preds)\n",
    "    scores_tf_idf_nb[3][model_num] = f1_score(y_test, preds)\n",
    "    return scores_tf_idf_nb, nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tf_idf_rf(X_train2, y_train, X_test2, y_test):\n",
    "    rf = RandomForestClassifier(n_estimators = 10, n_jobs=-1, random_state=0, class_weight = {0:.95, 1:.05})\n",
    "    rf.fit(X_train2, y_train)\n",
    "    predicted = rf.predict(X_test2)\n",
    "    pickle.dump(rf, open('tf_idf_rf_descrip'+ str(model_num) + '.p', 'wb'))\n",
    "    scores_tf_idf_rf[0][model_num] = accuracy_score(y_test, predicted)\n",
    "    scores_tf_idf_rf[1][model_num] = recall_score(y_test, predicted)\n",
    "    scores_tf_idf_rf[2][model_num] = precision_score(y_test, predicted)\n",
    "    scores_tf_idf_rf[3][model_num] = f1_score(y_test, predicted)\n",
    "    return scores_tf_idf_rf, rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_tf_idf_nb = np.zeros(shape=(4,9))\n",
    "scores_tf_idf_rf = np.zeros(shape=(4,9))\n",
    "\n",
    "model_num = 0\n",
    "start_month = 1\n",
    "end_month = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4 0\n",
      "tf_idf_nb\n",
      "[[0.73403153 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.93237032 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.39140022 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.55134925 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "tf_idf_rf\n",
      "[[0.94936126 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.76493762 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.93424218 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.84115523 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "2 5 1\n",
      "tf_idf_nb\n",
      "[[0.73403153 0.73084862 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.93237032 0.9194499  0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.39140022 0.38699008 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.55134925 0.54471387 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "tf_idf_rf\n",
      "[[0.94936126 0.94644495 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.76493762 0.73542895 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.93424218 0.94688027 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.84115523 0.82786583 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "3 6 2\n",
      "tf_idf_nb\n",
      "[[0.73403153 0.73084862 0.73377363 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.93237032 0.9194499  0.92461059 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.39140022 0.38699008 0.40097271 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.55134925 0.54471387 0.55936675 0.         0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "tf_idf_rf\n",
      "[[0.94936126 0.94644495 0.94283762 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.76493762 0.73542895 0.73956386 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.93424218 0.94688027 0.93391031 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.84115523 0.82786583 0.82545202 0.         0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "4 7 3\n",
      "tf_idf_nb\n",
      "[[0.73403153 0.73084862 0.73377363 0.73978957 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.93237032 0.9194499  0.92461059 0.91873863 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.39140022 0.38699008 0.40097271 0.41157294 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.55134925 0.54471387 0.55936675 0.5684803  0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "tf_idf_rf\n",
      "[[0.94936126 0.94644495 0.94283762 0.9420749  0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.76493762 0.73542895 0.73956386 0.75197089 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.93424218 0.94688027 0.93391031 0.92330603 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.84115523 0.82786583 0.82545202 0.82887701 0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "5 8 4\n",
      "tf_idf_nb\n",
      "[[0.73403153 0.73084862 0.73377363 0.73978957 0.73423324 0.\n",
      "  0.         0.         0.        ]\n",
      " [0.93237032 0.9194499  0.92461059 0.91873863 0.89251548 0.\n",
      "  0.         0.         0.        ]\n",
      " [0.39140022 0.38699008 0.40097271 0.41157294 0.41769818 0.\n",
      "  0.         0.         0.        ]\n",
      " [0.55134925 0.54471387 0.55936675 0.5684803  0.56907069 0.\n",
      "  0.         0.         0.        ]]\n",
      "tf_idf_rf\n",
      "[[0.94936126 0.94644495 0.94283762 0.9420749  0.93283912 0.\n",
      "  0.         0.         0.        ]\n",
      " [0.76493762 0.73542895 0.73956386 0.75197089 0.71243669 0.\n",
      "  0.         0.         0.        ]\n",
      " [0.93424218 0.94688027 0.93391031 0.92330603 0.92951542 0.\n",
      "  0.         0.         0.        ]\n",
      " [0.84115523 0.82786583 0.82545202 0.82887701 0.80662631 0.\n",
      "  0.         0.         0.        ]]\n",
      "6 9 5\n",
      "tf_idf_nb\n",
      "[[0.73403153 0.73084862 0.73377363 0.73978957 0.73423324 0.75079309\n",
      "  0.         0.         0.        ]\n",
      " [0.93237032 0.9194499  0.92461059 0.91873863 0.89251548 0.92350333\n",
      "  0.         0.         0.        ]\n",
      " [0.39140022 0.38699008 0.40097271 0.41157294 0.41769818 0.45656344\n",
      "  0.         0.         0.        ]\n",
      " [0.55134925 0.54471387 0.55936675 0.5684803  0.56907069 0.61103979\n",
      "  0.         0.         0.        ]]\n",
      "tf_idf_rf\n",
      "[[0.94936126 0.94644495 0.94283762 0.9420749  0.93283912 0.93725767\n",
      "  0.         0.         0.        ]\n",
      " [0.76493762 0.73542895 0.73956386 0.75197089 0.71243669 0.73447894\n",
      "  0.         0.         0.        ]\n",
      " [0.93424218 0.94688027 0.93391031 0.92330603 0.92951542 0.96014493\n",
      "  0.         0.         0.        ]\n",
      " [0.84115523 0.82786583 0.82545202 0.82887701 0.80662631 0.83228643\n",
      "  0.         0.         0.        ]]\n",
      "7 10 6\n",
      "tf_idf_nb\n",
      "[[0.73403153 0.73084862 0.73377363 0.73978957 0.73423324 0.75079309\n",
      "  0.73352822 0.         0.        ]\n",
      " [0.93237032 0.9194499  0.92461059 0.91873863 0.89251548 0.92350333\n",
      "  0.91777042 0.         0.        ]\n",
      " [0.39140022 0.38699008 0.40097271 0.41157294 0.41769818 0.45656344\n",
      "  0.42816684 0.         0.        ]\n",
      " [0.55134925 0.54471387 0.55936675 0.5684803  0.56907069 0.61103979\n",
      "  0.58391854 0.         0.        ]]\n",
      "tf_idf_rf\n",
      "[[0.94936126 0.94644495 0.94283762 0.9420749  0.93283912 0.93725767\n",
      "  0.93433776 0.         0.        ]\n",
      " [0.76493762 0.73542895 0.73956386 0.75197089 0.71243669 0.73447894\n",
      "  0.73399558 0.         0.        ]\n",
      " [0.93424218 0.94688027 0.93391031 0.92330603 0.92951542 0.96014493\n",
      "  0.92877095 0.         0.        ]\n",
      " [0.84115523 0.82786583 0.82545202 0.82887701 0.80662631 0.83228643\n",
      "  0.81997534 0.         0.        ]]\n",
      "8 11 7\n",
      "tf_idf_nb\n",
      "[[0.73403153 0.73084862 0.73377363 0.73978957 0.73423324 0.75079309\n",
      "  0.73352822 0.74968185 0.        ]\n",
      " [0.93237032 0.9194499  0.92461059 0.91873863 0.89251548 0.92350333\n",
      "  0.91777042 0.93257806 0.        ]\n",
      " [0.39140022 0.38699008 0.40097271 0.41157294 0.41769818 0.45656344\n",
      "  0.42816684 0.47770701 0.        ]\n",
      " [0.55134925 0.54471387 0.55936675 0.5684803  0.56907069 0.61103979\n",
      "  0.58391854 0.63178585 0.        ]]\n",
      "tf_idf_rf\n",
      "[[0.94936126 0.94644495 0.94283762 0.9420749  0.93283912 0.93725767\n",
      "  0.93433776 0.93611606 0.        ]\n",
      " [0.76493762 0.73542895 0.73956386 0.75197089 0.71243669 0.73447894\n",
      "  0.73399558 0.77728654 0.        ]\n",
      " [0.93424218 0.94688027 0.93391031 0.92330603 0.92951542 0.96014493\n",
      "  0.92877095 0.93424112 0.        ]\n",
      " [0.84115523 0.82786583 0.82545202 0.82887701 0.80662631 0.83228643\n",
      "  0.81997534 0.84856712 0.        ]]\n",
      "9 12 8\n",
      "tf_idf_nb\n",
      "[[0.73403153 0.73084862 0.73377363 0.73978957 0.73423324 0.75079309\n",
      "  0.73352822 0.74968185 0.75707899]\n",
      " [0.93237032 0.9194499  0.92461059 0.91873863 0.89251548 0.92350333\n",
      "  0.91777042 0.93257806 0.94676259]\n",
      " [0.39140022 0.38699008 0.40097271 0.41157294 0.41769818 0.45656344\n",
      "  0.42816684 0.47770701 0.51688924]\n",
      " [0.55134925 0.54471387 0.55936675 0.5684803  0.56907069 0.61103979\n",
      "  0.58391854 0.63178585 0.66869919]]\n",
      "tf_idf_rf\n",
      "[[0.94936126 0.94644495 0.94283762 0.9420749  0.93283912 0.93725767\n",
      "  0.93433776 0.93611606 0.94128167]\n",
      " [0.76493762 0.73542895 0.73956386 0.75197089 0.71243669 0.73447894\n",
      "  0.73399558 0.77728654 0.82877698]\n",
      " [0.93424218 0.94688027 0.93391031 0.92330603 0.92951542 0.96014493\n",
      "  0.92877095 0.93424112 0.93719492]\n",
      " [0.84115523 0.82786583 0.82545202 0.82887701 0.80662631 0.83228643\n",
      "  0.81997534 0.84856712 0.87965791]]\n",
      "CPU times: user 1h 30min 38s, sys: 50.4 s, total: 1h 31min 28s\n",
      "Wall time: 24min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "while end_month <13:\n",
    "    df_X_train, y_train, df_X_test, y_test = split_data(start_month, end_month) \n",
    "    X_train2, X_test2, tf_idf_vectorizer_train = run_tf_idf_vec(df_X_train, df_X_test)\n",
    "    scores_tf_idf_nb, nb = predict_tf_idf_nb(X_train2, y_train, X_test2, y_test)\n",
    "    scores_tf_idf_rf, rf = predict_tf_idf_rf(X_train2, y_train, X_test2, y_test)\n",
    "    print(start_month, end_month, model_num)\n",
    "    model_num += 1\n",
    "    start_month += 1\n",
    "    end_month += 1\n",
    "    print('tf_idf_nb')\n",
    "    print(scores_tf_idf_nb)\n",
    "    print('tf_idf_rf')\n",
    "    print(scores_tf_idf_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF IDF NAIVE BAYES SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7404176382546709\n",
      "0.9231443684365492\n",
      "0.4319956286015536\n",
      "0.5876026924060398\n"
     ]
    }
   ],
   "source": [
    "accuracy_2017_tf_idf_nb = np.mean(scores_tf_idf_nb[0])\n",
    "recall_2017_tf_idf_nb = np.mean(scores_tf_idf_nb[1])\n",
    "precision_2017_tf_idf_nb = np.mean(scores_tf_idf_nb[2])\n",
    "f1_score_2017_tf_idf_nb = np.mean(scores_tf_idf_nb[3])\n",
    "print(accuracy_2017_tf_idf_nb)\n",
    "print(recall_2017_tf_idf_nb)\n",
    "print(precision_2017_tf_idf_nb)\n",
    "print(f1_score_2017_tf_idf_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF IDF RANDOM FOREST SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9402834453899148\n",
      "0.7532084507262276\n",
      "0.9364673471514087\n",
      "0.8344959114674015\n"
     ]
    }
   ],
   "source": [
    "accuracy_2017_tf_idf_rf = np.mean(scores_tf_idf_rf[0])\n",
    "recall_2017_tf_idf_rf = np.mean(scores_tf_idf_rf[1])\n",
    "precision_2017_tf_idf_rf = np.mean(scores_tf_idf_rf[2])\n",
    "f1_score_2017_tf_idf_rf = np.mean(scores_tf_idf_rf[3])\n",
    "print(accuracy_2017_tf_idf_rf)\n",
    "print(recall_2017_tf_idf_rf)\n",
    "print(precision_2017_tf_idf_rf)\n",
    "print(f1_score_2017_tf_idf_rf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
